
elastisearch的13天课程，
14天的课程看到 4.商品微服务添加api接口.avi，然后因为写了BrandApi这个类，没看懂，所以又回去从11天开始看了

CollectionUtils 这个是spring框架提供的
StringUtils这个是apache common包提供的，同样的还有NumberUtils等好多好多的工具类

xmind思维导图工具，比较好用

微服务的各个服务启动，是没有先后顺序的，我以前理解还有先后顺序，比如你先启动其他的服务，最后再启动注册中心，注册中心也可以扫描得到已经启动的微服务

单独把所有的pojo发布在一个微服务里面，pojo这个是一个聚合工程，其他的微服务工程只需要引入就行了
比如你数据库表增加一个字段，删除一个字段，那别人会不会想死啊，我们现在就要去搭建这样一个聚合module
怎么声明这个工程是一个聚合工程呢？ 
<packaging>pom</packaging>  ，就是把这个模板声明为pom，即声明这个工程为一个聚合模块
比如leyou-item工程已经创建好了，类型为pom类型
那么他包含哪些子模块呢？ 此时选中leyou-item，针对这个项目再创建子模块 New Module
leyou-item-interface为什么取这样名字呢？ 因为我们现在只是放pojo对象进去，将来还会放别的东西进去，比如自定义异常 
接着再创建一个 module  leyou-item-service  这个是微服务模块

本项目使用的版本为：springcloud版本：Finchley.SR2   springboot版本  2.0.6
Finchley.SR1 里面有很多bug

工程命名，比如注册中心，我们使用 leyou-registry  为什么不写 leyou-eureka呢？ 哪天我注册中心使用的技术变了，你这个项目名还是这样，是不是很尴尬啊，所以我们
尽量不把这个工程名给成技术名给写死了


idea快速上手指南.md   注意idea在yml文件里面写，其实还是有很多东西是没有提示的，比如配置熔断时间
jdk8新特性.md
markdown了解一下    https://www.runoob.com/markdown/md-tutorial.html

出去面试千万别说自己的项目用的mysql5.5的，5.5是不支持集群的，你去互联网公司面试，没做过mysql集群的项目，你说别人会怎么想



1. @RestController  相当于Control类中定义的方法上面加了一个  @ResponseBody

	如果只是@Controller类，那么里面的方法上面 只有加@ResponseBody这个方法才能返回json内容，否则都是返回视图，路径之类的

2. @SpringBootApplication注解相当于是几个组合的注解
				@SpringBootConfiguration
				@EnableAutoConfiguration
				@ComponentScan
				
	`@Configuration`：声明这个类是一个配置类
	在类上通过@ConfigurationProperties注解声明当前类为属性读取类
	
3. 在代码里面写this.url 其实就是使用全局的变量，
	@Value("$jdbc.url")
	public String url;
	public DataSource dataSource(){    //如果在这个方法里面使用（String url） ，则方法体内不能使用this.url了
		DruiDataSource dataSource = new DruiDataSource();
		dataSource.setUrl(this.url);  
	}
	
4. 注入的方式：
	- 然后你可以通过以下方式注入JdbcProperties：

  - @Autowired注入    这种是最符合我们的书写习惯的

    ```java
    @Autowired
    private JdbcProperties prop;
    ```

  - 构造函数注入

    ```java
    private JdbcProperties prop;
    public JdbcConfig(Jdbcproperties prop){
        this.prop = prop;
    }
    ```

  - 声明有@Bean的方法参数注入

    ```java
    @Bean
    public Datasource dataSource(JdbcProperties prop){
        // ...
    }
    
    
        @Bean
    // 声明要注入的属性前缀，SpringBoot会自动把相关属性通过set方法注入到DataSource中
    @ConfigurationProperties(prefix = "jdbc")   用这种方式写，有很大的局限性，比如属性一个字母都不能写错，看得懂这种代码就行
    public DataSource dataSource() {
        DruidDataSource dataSource = new DruidDataSource();
        return dataSource;
   	 }
	}
5.  
	/**
     * 重写接口中的addInterceptors方法，添加自定义拦截器
     * @param registry
     */
    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        // 通过registry来注册拦截器，通过addPathPatterns来添加拦截路径
        registry.addInterceptor(this.loginInterceptor()).addPathPatterns("/**");  /**拦截多级（包含子孙级路径）    /*只拦截一级
    }

6. 垂直拆分，其实就是功能的拆分，如购物车模块，用户模块，订单模块
       水平拆分，其实就是代码分层，web层，service层，mapper层
       
   传统架构--》水平拆分（代码分层）--》垂直拆分（最早的分布式）--》soa（最早dubbo框架说自己是soa，现在dubbo也说自己是微服务了）--》微服务

7. 	这种微服务分布式，还可以做数据独立，用户团队，只就能拿到用户那几张表，订单团队就只能拿到订单那几张表，购物车团队就只有购物车那几张表，
	每个团队都拿不到一份完整的数据，这样就最大程度上保证了数据的安全
	
8. 阿里为什么要花大钱去研发数据库，为什么不使用oracle，直接买Oracle肯定便宜啊，但你要数据定向优化的话，你得把你的全部数据结构给他，别人才能优化得了
	如果你只把表结构给他，数据不给别人，别人也帮你优化为不了，所以阿里不使用oracle
9. 2012年开始dubbo就不维护了，springcloud起来了，dubbo2017年又开始维护并交给apache了
	因为没人维护了，所以有些场景就适用不了了，所以springcloud就起来了，如果一直维护，那么springcloud就火不起来了
	因为dubbo太简单了
	
	RPC与RMI的区别

 1：方法调用方式不同：

  RMI中是通过在客户端的Stub对象作为远程接口进行远程方法的调用。每个远程方法都具有方法签名。如果一个方法在服务器上执行，但是没有相匹配的签名被添加到这个远程接口(stub)上，那么这个新方法就不能被RMI客户方所调用。

  RPC中是通过网络服务协议向远程主机发送请求，请求包含了一个参数集和一个文本值，通常形成“classname.methodname(参数集)”的形式。RPC远程主机就去搜索与之相匹配的类和方法，找到后就执行方法并把结果编码，通过网络协议发回。

 2：适用语言范围不同：

  RMI只用于Java；

  RPC是网络服务协议，与操作系统和语言无关。

 3：调用结果的返回形式不同：

  Java是面向对象的，所以RMI的调用结果可以是对象类型或者基本数据类型；

  RMI的结果统一由外部数据表示 (External Data Representation, XDR) 语言表示，这种语言抽象了字节序类和数据类型结构之间的差异。

	
10. soa，微服务，都是面向服务的，但微服务粒度更细，比如soa把订单跟购物车搞在一起提供服务，微服务就不会这样

11. 可以在有@SpringBootApplication注解的类中写一个  @Bean的方法，实现注入，因为@SpringBootApplication是一个组合组合注解，就包含配置注解的功能

12. eureka你在浏览器上面访问的时候，直接http://localhost:10086这样就可以访问到了，不需要 http://localhost:10086/eureka，但是在eureka项目的配置文件中
	需要加上，这个在eureka的官方文档中也没说为什么

13.	eureka控制台页面上的  PS-1:demo-eureka:10086  这个即注册的服务，    计算机名+微服务名+端口号组成的
	 DEMO-EUREKA	n/a (1)	(1)	UP (1) - PS-1:demo-eureka:10086

14.  @EnableEurekaClient我们的服务提供者工程itcast-service-provider里面的启动类上可以使用这个注解，但我们经常使用 @EnableDiscoveryClient //这个是发现者的客户端，其实也是启用eureka客户端
		@EnableEurekaClient 这个是netfix组件提供的
		 @EnableDiscoveryClient这个是springcloud提供的，我们当然使用这个啦 ，推荐使用这个，兼容性肯定更好啦
		 
15. 像eureka，可以两个相互注册，还可以多个各自相互注册，相互知道对方的存在，比如10个，你就围成一圈不就行了

16. 什么是springcloud
	是一种微服务架构的解决方案，是很多组件的集合
	eureka:注册中心，服务的注册与发现，只专门负责这个
	zuul：网关组件，路由请求，过滤器(ribbon,hystrix),因为zuul跟feign都是一个组件，都需要去调用微服务，所以都需要使用ribbon,hystrix
	ribbon:负载均衡组件
	hystrix:熔断组件
	feign:远程调用组件（ribbon hystrix）
	
	通常ribbon,hystrix这两个我们不是直接去玩的，是通过feign  zuul去玩的
	
	不论服务提供方，服务消费方，在itcast-eureka工程看来，你们都是客户端，都需要在我这注册，我才是@EnableEurekaServer
	
	
17. 一般负载均衡是一个团队去写的，不会使用默认的，因为默认的就只有轮询，随机，这两种都无法满足真实的业务场景，
	比如：机器的CPU的核数不一样，硬件处理能力不一样，你轮询，随机，还是把这些机器均等的处理，这显然就不太对
	
18. demo-service-provider: #服务提供方的服务名，或服务ID
  ribbon:
    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #这个是随机的算法，
	这个是配置这个负载均衡算法的，当然要配置在消费者工程里面了
	
	随机，轮询，你在访问量大的情况下，都是5 5开的，其实都一样
	
19. 既然远程调用，是不是可能调用失败，是不是可能高并发啊，所以我们需要集成 hystix
	由于所有的请求经过zuul，所以他才是最有可能遇到高并发，所以需要集成ribbon
	
	玩熔断，应该在consumer即调用方里面去玩
	
	//定义熔断方法：局部（要和被熔断的方法返回值和参数列表一致）  全局（返回值类型要和被熔断的方法一致，参数列表必须为空）
	
20. 配置熔断时间，这个
	hystrix:
  command:
  	default:
        execution:
          isolation:
            thread:
              timeoutInMillisecond: 6000 # 设置hystrix的超时时间为6000ms
			  
21. 一个服务消费者工程的启动类上面的注解如下：
	@SpringBootApplication
	@EnableDiscoveryClient
	@EnableCircuitBreaker //开启熔断Hystix
	加这么多，是不是很烦啊，有什么办法吗？
	@SpringCloudApplication  这是一个组合注解，用这一个就可以了
	
	
	hystrix	
		降级
			1.引入hystrix启动器
			2.熔断时间，默认为1s，6s
			3.在引导类上添加一个注解：@EnableCircuitBreaker
			4.定义熔断方法：局部（要和被熔断的方法返回值和参数列表一致） 全局（返回值类型要和被熔断的方法一致，参数列表必须为空）
			5.
		熔断：
			1. close:闭合状态
			2.open 打开状态
			3. 半打开状态
			
很多个人干同一件事这就是集群，很多人干不同的事，就是分布式

秒杀并不代表高并发，其实就是一个限流操作

缓存技术：减少每次请求的访问时间

静态化技术：把高频的页面，进行静态化，直接存到数据库里面，减少渲染，比如商品页面

异步并发：其实就是消息队列技术

池化：tomcat线程池

vue + mongodb 也完全可以开发项目，不用去养后端java人员了


每一个刚开始的项目都是最完美的项目，由于需求反复改，每一个已经上线的项目，都是最垃圾的项目，我现在做的已经改得不成样子了


vue.js基于node.js环境，node.js相当于java中的jdk
webpack类似于tomcat，我们借助于webpack来热部署
npm相当于java中的maven，用来下载依赖包
Vuetify提供了用vue写的组件，你只要组装一下就可以形成页面
NUXT：这个在项目的时候会详细讲

通过nginx对zull做负载均衡，

比如商品详情页这种静态资源页，我们可以通过nginx配置就可以访问了，就不用再通过zull网关了

前台系统我们会使用Thymeleaf模板引擎技术来完成页面开发，出于SEO优化考虑，我们将不采用单页应用，即：每一个页面都是一个独立的html页面

1. 因为eureka,feign以及zuul已经集成ribbon的依赖，所以我们很少会直接去使用ribbon

2. 删除了register-with-eureka=false和fetch-registry=false两个配置。因为默认值是true，这样就会吧自己注册到注册中心了。
	如果eureka做集群的话，上面那两个配置绝对不能配置啊，你自己都不注册到注册中心了，我怎么做集群啊，对吧


---------------下面为前端项目了
原来我们使用var来定义一个变量，这种定义有什么缺陷呢？  当然是变量越界吧，比如我在循环里面
for ( var i=0;i<5;i++){
        console.log(i);
    }

    console.log("我在循环外" + i); 
    
    控制台，把i=5也打印出来了，这种是不是不合适啊
    
    for ( let i=0;i<5;i++){  以后我们就这么写吧
        console.log(i);
    }
    
    const i=100;
    i=1; 立马报错 ，const是声明一个常量，不允许修改

箭头函数    ()=>{}    如果只有一个参数，并且只有一行代码，就是  s => parseInt(s)

现在已经很少去直接玩jquery了

MVVM就是MVC的一个分支，本质就是MVC

npm:node package manager

通过cdn的方式安装vue，这种适合上线后可以采用的方式，如：
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
是有人买了代理服务器，把这个vue放到服务器上


package.json这个文件，相当于java项目中的pom.xml

在操作系统的任意路径下，在打开的窗口路径上，把，如：E:\code\demo-es6\hello-vue　删除，敲入　cmd，则会直接进入cmd窗口


不要使用 <script src="node_modules/vue/dist/vue.js" /> 在vue里面会失效，这是一个坑啊，千万要记住，你使用这个简写，又不会报错，但就是没效果
<script src="node_modules/vue/dist/vue.js"></script>


	
----------vue的生命周期
beforeCreated：我们在用Vue时都要进行实例化，因此，该函数就是在Vue实例化时调用，也可以将他理解为初始化函数比较方便一点，在Vue1.0时，这个函数的名字就是init。 

created：在创建实例之后进行调用。 

beforeMount：页面加载完成，没有渲染。如：此时页面还是{{name}}

mounted：我们可以将他理解为原生js中的window.onload=function({.,.}),或许大家也在用jquery，所以也可以理解为jquery中的$(document).ready(function(){….})，他的功能就是：在dom文档渲染完毕之后将要执行的函数，该函数在Vue1.0版本中名字为compiled。 此时页面中的{{name}}已被渲染成峰哥

beforeDestroy：该函数将在销毁实例前进行调用 。

destroyed：改函数将在销毁实例时进行调用。

beforeUpdate：组件更新之前。

updated：组件更新之后。


莫莫 用这个，这个不合适，这个都是选渲染完了，然后再去执行更新操作，再次渲染，虽然跟直接使用created的作用是一样的，但是你这个做了多余的操作
mounted(){
		this.init();
	},
	
	
	---像下面这个，直接使用create()即可 
const app = new Vue({
        el: "#app", //element,选择器
        data: {  //定义数据模型
            name: "刘德华",
            num: 100
        },
        methods: {
            incr(){
                //下面这个this可以操作这个id为app内的任意内容
                console.log(this); //打印一下这个this是什么东西，注意要触发到这个方法才可以打印到this啊，你也可以把这个写到上面去
                this.num++;
            }
        },
        created(){
            //ajax
            this.num = 10000;
        }
    })


chrome浏览器还有设置网速慢的功能，按F12,在NewWork里面选择 slow 3G
大家好，我是{{name}}，有{{num}}位妹子迷恋我,此时可以看到页面显示成了花括号了，是不是不友好啊，所以我们要使用 v-text,可是我们不能直接使用v-text啊，我们可以定义一个span标签


v_text 用得最多，但很多人也用｛｛｝｝，因为程序员都懒 ，v_text还可以防止攻击

上面讲的都是单向数据绑定，上面那些只能展现数据，不能修改数据，我们应该在表单数据里面去使用v_model,
刚才的v-text和v-html可以看做是单向绑定，数据影响了视图渲染，但是反过来就不行。接下来学习的v-model是双向绑定，视图（View）和模型（Model）之间会互相影响。

既然是双向绑定，一定是在视图中可以修改数据，这样就限定了视图的元素类型。目前v-model的可使用元素有：

- input
- select
- textarea
- checkbox
- radio
- components（Vue中的自定义组件）

基本上除了最后一项，其它都是表单的输入项。

v-if  v-show这两个的效果一样，但本质是完全不同的
v-if如果条件不满足，就压根不渲染，v-show一定会渲染，只是把这个dom元素设置为隐藏，我们通常使用v-if会更加灵活

v-if v-for

computed这个是计算属性

在vue里面，所有的实例，他都认为是一个组件

一加载一个vue工程，我们第一件事，就是去看package.json，看引入了哪些依赖和组件，比如webpack就是打包，热部署的时候才会用到，运行的时候不会用到了
devDependencies这个就是开发依赖，比如下面有很多可以将高级版本的语法转为低版本浏览器支持的语法，一旦编译好了，就不需要了

比如我现在打开了leyou-manage-web这个工程，是不是里面没有node_modules啊，运行一下，下面这个命令
npm install 
如果下载的时候出错，也可以去同事的电脑上拷贝一份过来也行


"scripts": {
    "dev": "webpack-dev-server --inline --progress --config build/webpack.dev.conf.js",
    "start": "npm run dev",   //请看下面的说明
    "build": "node build/build.js"
  },
  
现在执行：npm run dev命令，本质上就是去运行上面的webpack的命令 webpack-dev-server --inline --progress --config build/webpack.dev.conf.js
就是通过webpack去运行的

其实我们可以：npm start也可以运行，就是使用了"start"这个，本质上也还是去运行上面的webpack命令
因为使用了webpack热部署，所以页面发生改变的时候，就自动生效了，而且不用你浏览器去刷新，浏览器会自动刷新

我们的build目录下面是不是有webpack的配置文件啊
config目录：webpack运行所需要的环境参数
dist目录：打包的一个目录

我们的后台leyou-manage-web是一个单页应用，所以就一个index.html页面，其他的所有内容都是组件

src下面的assets下面就是一些资源 

components里面定义了一些全局的组件，比如树组件，级联组件

pages：页面，页面本质上也是组件，

.vue的文件里面：
<template>标签中定义模板
<script>标签中定义脚本
<style>标签中定义样式，
采用这样的结构，是不是代码相当的清晰呢？  答案是肯定的

import router from './router' //如果你这个目录下面只有一个js文件，并且这个文件是index.js文件，是可以省略的
直接通过目录的形式来导入这个文件

vue是基于js的一个框架，类似于jquery也是基于js的一个框架
Vuetify是基于vue的一个框架

我们使用vuetify框架，为什么不用bootstrap layui easyui zui这些呢？
因为他们天生与vue不合，他们是操作dom的

像一级域名：www.leyou.com 是需要花钱买的，二级域名 manage.leyou.com就可以随便开了

我们在host文件中配了127.0.0.1 manage.leyou.com
leyou-manage-web这个vue项目运行的状态，还是无法通过http://manage.leyou.com:9001/#去访问，为什么呢？
此时我们需要禁用开发阶段的localhost检查，修改webpack.dev.conf.js，在里面添加
disableHostCheck: true //开发阶段禁用localhost检查

注意，你改了webpack配置文件，就需要重启项目了，现在改好了，但访问地址还是：
http://manage.leyou.com:9001，后面有端口，是不是很不爽啊
要把这个端口去掉，
这时候，我们就需要使用nginx做代理了，由nginx给我们监听80端口，由nginx给代理到不同的端口地址去

正向代理，代理的是用户，反向代理，代理的是服务器，

注意：web应用服务器跟web服务器的区别：
web应用服务器，可以解析jsp，servlet之类的
web服务器，只能处理一些静态资源，静态的页面，图片，css等，不能解析jsp，功能上有点弱化，但性能很高

nginx动态路由：比如说我们就可以动态路由到不同的端口上去

其实你访问很多的互联网应用，都是使用nginx+tomcat这样一套解决方案，
前面用nginx做代理，负载均衡，再请求到相应的微服务

Tengine这个是淘宝网发起的web服务器，是在nginx上做的一个封装

nginx程序的目录：D:\ProgramFiles\nginx-1.12.2\html 
比如html目录，将来我们做商品页面的静态化，我们就会把商品的页面放在这个目录下

D:\ProgramFiles\nginx-1.12.2\conf 这个是nginx的配置文件目录
worker_processes  1;配置文件中的这个配置，就是工作进程的意思  1代表1个，这个工作进程我们应该配多少个呢？
通过不超过计算机的核数，比如8核CPU我们就配成8个

注意nginx是永远不需要重启的，一旦启动，基本上不会宕机的，你改了配置文件，只需要
nginx -s reload 重新加载一下就行了，停止的话，就是  -s stop

events {
    worker_connections  1024;  //这个是配置一个工作进程，里面允许的最大连接数
}


Vuetify优点：
https://blog.csdn.net/weixin_41249041/article/details/89439570   值得一看
几乎不需要任何CSS代码，而element-ui许多布局样式需要我们来编写
Vuetify从底层构建起来的语义化组件。简单易学，容易记住。
Vuetify基于Material Design（谷歌推出的多平台设计规范），更加美观，动画效果酷炫，且风格统一

如何用 Vue + Vuetify 快速建站？
https://blog.csdn.net/wingalong/article/details/93001259

项目开发常见几种模式：
1.api文档先行，api接口已经定义好了
前端，后台都根据api文档进行，同时开发

2.前端页面开发好
后台  基于前端的调用关系去开发

3. 后台开发好
前台  根据后台的接口去开发

现在我们来编写商品分类，我们根据vue项目地址栏上路由的路径，找到商品分类页面Category.vue
 <v-tree url="/item/category/list"
                :isEdit="isEdit"
                @handleAdd="handleAdd"
                @handleEdit="handleEdit"
                @handleDelete="handleDelete"
                @handleClick="handleClick"
        />
v-tree 这个即不是vue提供的，也不是vuetify提供的，这是我们的自定义组件，不要求你能看得懂，因为里面用了很多高级的
语法，这个已经定义成了一个全局的组件，在MyComponent.js文件中已经有引入了


----下面开始编写后台代码了
@GetMapping("/list")
    public ResponseEntity<List<Category>> queryCategoryByPid(@RequestParam("pid") Long pid){}
    
    如果pid参数不传，这个接口是不是会报错啊,所以我们下面这样定义，默认查顶级类目的
    public ResponseEntity<List<Category>> queryCategoryByPid(@RequestParam(value="pid",defaultValue="0") Long pid){}

如<img src=>  还有其他的标签有src属性的，其实src的本质就是发起一个get请求

nginx可以通过代理模式把跨域问题，变成不跨域问题，这种解决方案本质是一种逃避的行为

在有cros方案的情况下，jsonp ,nginx的跨域解决方案都不采用，而且在nginx里面配置，不符合devops思想

像这种跨域问题，我们是不是应该放在网关里面才最合适啊，因为所有的请求都是放在网关里面

$emit("调用父组件的方法");

qs工具，可以把查询字符串转成json,也可以把json转成查询请求字符串，区别在于
请求的时候，如果是json发起对后端的请求，那么就是带{}括起来的
查询字符串为： http://localhost:8080/getCustomer?key1=xxx&name=xxx


文件上传：
我们原来springmvc是不是需要在xml中定义,而springboot项目，这个已经自动注入了，我们只需要在controller中使用文件上传的spring类即可
<bean id="" class="CommonsMultipartResolver">
	<property defaultEncoding>
	<property max-uploadsize>
</bean>

但是，我们还是要把这个文件上传的编码，文件上传的大小，配置在yml文件中
spring:
	application:
		name:
	servlet:
		multipart:
			max-file-size:5MB
			
文件上传，可以使用nginx代理到图片路径：
修改nginx.conf配置文件
server {
        listen       80;
        server_name  image.leyou.com;

        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header X-Forwarded-Server $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        location / {
			root: G:\\LeYou\\upload;  代理到这个路径
        }
    }
然后在浏览器上可以:http://image.leyou.com/xxx.jpg  
那么只要放在G:\\LeYou\\upload路径下的文件，就可以通过敲地址栏进行访问了

我们要想办法，让图片上传这些绕过网关，减轻网关的压力，因为文件操作，非常占用资源
绕过网关，有两种思路，一种是在网关里面配置，让网关忽略一些/upload路径或者忽略upload-server微服务，但是这两种配置方法
都不可取，这样还是经过网关了，我们应该直接在nginx里面配置

配置如下:
server {
        listen       80;
        server_name  image.leyou.com;

        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header X-Forwarded-Server $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        location /api/upload {
        //这个路径是不是好怪，我们现在配置这个请求不经过zuul了，但前面还是有api字符，如果我们在前端项目中改，那么又影响到别的baseUrl了，这个时候就要用到nginx的路径重写了
			//proxy_pass http://127.0.0.1:8082/api/upload/image;
			//proxy_pass http://127.0.0.1:8082/upload/image;//这个是使用下面的重写之后的路径
			proxy_pass http://127.0.0.1:8082;
			proxy_connect_timeout 600;
			proxy_read_timeout 600;
			
			rewrite "^/api/(.*)&" /&1 break; //小括号是正则里面的分组表达式，一对小括号是一组，二对就是二组,注意/&1 这个是匹配第1组 ,&1这个是数字1
        }
        location / {
			proxy_pass http://127.0.0.1:10010;
			proxy_connect_timeout 600;
			proxy_read_timeout 600;
        }
    }

location /api/upload {
location / {
注意这两个的顺序，不能颠倒，一定是先判断路径是否是服务器路径，如果是则路由到文件上传微服务，否则路由到10010

正则表达式: /^&/  都是以^开头,&结尾

现在配置的文件上传微服务，不经过网关了，原来在网关里面写的那个跨域的过滤器，是不是对文件上传不起作用了啊
所以把原来写的那个copy一份到文件上传微服务里面来，不就行了


FastDFS是最轻量级的分布式文件系统，比其他的GFS,HDFS都要轻很多，也是
很多互联网公司比较流行的一个分布式文件系统

fastdfs，数据存储是分组的，组与组之间数据是不一样的，组内部数据是一样的
我客户端我要上传一张图片，我需要先去访问跟踪（踪迹）服务器，这个跟踪（踪迹）服务器就相当于一个管理中心

在顶级工程，leyou的pom中定义的
 <!--这个就是在父工程里面定义，在子工程里面只需要引入，而不需要指定版本号，dependencyManager的作用，还记得不？-->
        <dependency>
            <groupId>com.github.tobato</groupId>
            <artifactId>fastdfs-client</artifactId>
        </dependency>
上面这个我就是在leyou-upload工程里面定义的



你要先搜索，是不是要先整好商品的规格参数呢？当然是的了

我们设计一个加一个字段，是否是数字，就是在页面上做搜索的时候，比如你这个属性，电池容量属性，你设计他是一个数字，然后在做搜索的时候，是不是就有2000mah以下，2000-3000mah之类的区间啊
你属性是数字的时候，就需要指定单位


比如你把数据导入到elatisearch索引库，你是不是要分批查询spu,转化成goods,才能导入索引库
一定是分批查询spu，然后导入索引库，因为

分批查询List<Spu>转化成List<Goods>，才能导入索引库


点开一个商品详情，上面是不是有一条面包屑啊
手机>手机通讯>手机>Apple>Apple iPhone 6s
这种上面的背后必然是一个id,我们可以封装成如下的数据结构
List<Map<String, Object>> categories
像Apple这个是品牌的id啊
Apple iPhone 6s是spu里面的title


声明一个类,indexName指定索引库名, type:指定表名,shards分片数量，replicas：指定副本
@Document(indexName = "item", type="docs"， shards = 1, replicas=0
public class Item{
	
}


我们只需要声明一个接口继承ElasticsearchRepository就可以使用elasti的增删改查的功能了，不信你看ElasticsearchRepository接口的继承体系
public interface GoodsRepository extends ElasticsearchRepository<Goods,Long> {
}

就可以在别的类直接下面这样使用了，哎，奇怪啊，我声明了GoodsRepository接口，我并没有写实现类啊，怎么可以直接注入了呢？
这有点类似于mybatis的通用mapper啊 
@Autowired
GoodsRepository goodsRepository;



goodsRepository.save(entity);
goodsRepository.saveAll(list);
注意elastic没有修改的方法，你重新save不就是修改嘛



idea工具还有自动代码生成的功能
this.brandMapper.selectByExample(example).var 此时回车，就会自动生成
List<Brand> brands=this.brandMapper.selectByExample(example);


@Test
public void testFind(){
	Iterable<Item> items = this.itemRepository.findAll(Sort.by("price").desceding());
	items.forEach(System.out::println);//注意这也是jdk8的语法
	
	System.out这个相当于调用System out的静态方法，哪一个静态方法？println这个静态方法，这个静态方法
	需要输入一个参数，然后items.forEach就会输出一个参数，这不刚好，一个输入，一个输出，不就打印出来了吗？
}



public interface ItemRepository extends ElasticsearchRepository<Item, Long> {
	List<Item> findByTitle(String title);
}

就这么声明一下，就可以使用了
@Test
public void testFindByTitle(){
	Iterable<Item> items = this.itemRepository.findByTitle("手机");
	items.forEach(System.out::println);//注意这也是jdk8的语法
}
为什么我可以直接声明一个findByTitle就可以使用了呢？
原来在ElasticsearchRepository中已经按规则定义了一些实现方法了，
有findByName,比如你可能不叫Name，你改成findByTitle也行，他定义的是
findBy这样的前缀，这个叫做他定义了很多方法模板

findByNameAndPrice ，这这个Name和Price你可以掉掉



比如说你jd搜索出来的结果页面，你搜一个手机
规格参数是不是有很多啊，而且是不确定性的，我们就通过一个Map来存储
Map<name, value>


@Field(type = FieldType.Keyword, index = false)//index=false 代表不创建索引
    /**
     * 卖点
     */
    private String subTitle;
    /**
     * 品牌id
     */
    private Long brandId;
    /**
     * 1级分类id
     */
    private Long cid1;
    /**
     * 2级分类id
     */
    private Long cid2;
    /**
     * 3级分类id
     */
    private Long cid3;
	
你看，好多字段，我没加注解啊，这个elatisc有智能判断




下面这个value是告诉我们的feign客户端，我们的微服务是哪个
@FeignClient(value = "item-service")
public interface GoodsClient{

	/**
     * 根据spu商品id查询详情
     * @param id
     * @return
     */
    @GetMapping("/spu/detail/{id}")
    public ResponseEntity<SpuDetail> querySpuDetailBySpuId(@PathVariable("id") Long id){ }
	我们把放在GoodsController类中的方法拷贝过来就行了，注意这个返回值
	你可以写成ResponseEntity<SpuDetail>，也可以直接写成
	@GetMapping("/spu/detail/{id}")
    public SpuDetail querySpuDetailBySpuId(@PathVariable("id") Long id){ }
	，如果你写成ResponseEntity<SpuDetail>，你使用的时候还需要去解包，因为ResponseEntity是一个复合对象
	而你如果直接写成SpuDetail就可以直接使用了
}
其实我们这个feign客户端里面的方法，不是这么去玩的，我现在这个是直接从别人的GoodsController类中copy过来的
一般情况下，你怎么知道别人有哪些接口，别人哪些接口的返回值啊，别人接口又改了呢？
所以就明白了，我之前看不懂的代码，直接使用
@FeignClient(value = "item-service")
public interface GoodsClient extends GoodsApi {
}
这个GoodsApi就是在接口提供方的工程里面，像这些接口工程，即使在大型公司，肯定也是共享的啊

你想啊，谁对这个接口最熟悉啊，肯定是谁开发的谁最熟悉啊，所以我们就继承别人开发的那个接口就行了
这样还有一个好处，就是这个方法这个接口，在整个系统里面只需要定义一遍就行了


原来他写的Service层，都是这样的
@Service
public class SearchService{
	public Goods buildGoods(Spu spu){
		Goods goods = new Goods();
		
		
		return goods;
	}
}

如果你将来用接口的方式写的话，那么这个@Service注解就是放在实现层上了，原来我就是在这浪费了好久 的时间找错
@Service
public class SearchServiceImpl  implements SearchService {
	public Goods buildGoods(Spu spu){
		Goods goods = new Goods();
		
		
		return goods;
	}
}


我们给goods索引数据模型设置这个all上面的值，为什么要加空格呢？
goods.setAll(spu.getTitle() + " " + StringUtils.join(names, " "));

水电费水电费电费，你这样拿给他，他去分词，是不是有可能会分出费电，这个词出来？答案是肯定的啊，为了
防止这种问题，所以我们加入空格


List<OrgEntity> orgList = new ArrayList<>(); 后面这个尖括号里面的OrgEntity可以不写的
List<Map<String, Object>> skuMapList = new ArrayList<>();  可以简写的


下面的序列化与反序列化
private ObjectMapper mapper = new ObjectMapper();
goods.setSkus(mapper.writeValueAsString(skuLists)); 将一个对象序列化为json字符串

下面的为将json字符串反序列化为Map结构的数据，因为规格参数是动态的，所以使用map来封装
注意：TypeReference这个是一个高级语法，List<Map<String,Object>>指定你需要反序列化的类型
//提取公共属性
List<Map<String,Object>> genericSpecs = mapper.readValue(spuDetail.getSpecifications(),new TypeReference<List<Map<String,Object>>>(){});
//提取特有属性
Map<String,Object> specialSpecs = mapper.readValue(spuDetail.getSpecTemplate(),new TypeReference<Map<String,Object>>(){});



比如现在我们的索引查询程序做好了，但是没有商品这些的索引库啊，在正式的公司里面，我们也只导入一遍，
写个测试用例导都可以，第一次初始化的时候需要导入，后面数据同步，都是通过程序去完成的，导入数据只导入一次
只要把数据导入进去就行了


像京东的查询结果页，是不是只有下一页，下一页啊，每页显示多少条也没有设置的地方，天猫淘宝也是一样的
你如果在这种前台做用户可以设置每页多少条，是很危险的，别人使用httpclient工具，直接设置一个最大值，你所有的数据就会给别人导走了
京东每页显示是按4的倍数进行显示的，我们乐优是按5的倍数进行显示的
你如果不进行约定，那么页面是不是就会变形啊


mybatils plus的自动生成get set方法，有时候还是不满足，比如
public class SearchRequest {

    /**
     * 搜索条件
     */
    private String key;

    /**
     * 当前页
     */
    private Integer page;
	
	/**
     * 每页大小，不从页面接收，而是固定大小
    */
    private static final Integer DEFAULT_SIZE = 20;

    /**
     * 默认页
     */
    private static final Integer DEFAULT_PAGE = 1;

这是一个查询pojo对象，你这个page如果只是简单的get方法的话，就做不了如下的默认逻辑了

 public Integer getPage() {
        if (page == null){
            return DEFAULT_PAGE;
        }
        /**
         * 获取页码时做一些校验，不能小于1
         */
        return Math.max(DEFAULT_PAGE,page);
    }
	
	每页查询的数据量大小，使用默认值
	public Integer getDefaultSize() {
        return DEFAULT_SIZE;
    }
	
｝



@RequestBody SearchRequest //使用@RequestBody 设置此接口传入的参数为json参数，使用SearchRequest对象进行接收
还是要使用这种方式
@PostMapping("page")
    public ResponseEntity<PageResult<Goods>> search(@RequestBody SearchRequest searchRequest){
        SearchResult<Goods> result = this.searchService.search(searchRequest);
        if (result == null){
            return new ResponseEntity<>(HttpStatus.NOT_FOUND);
        }else {
            return ResponseEntity.ok(result);
        }
    }
	
现在通过elatisearch搜索出来，返回给前端的结果集里面，有很多cid：null等这样的字段
我们在search工程里面的application.yml配置文件里面配置
Spring:
	application:
		name: search-service
	data:
		elaticsearch:
			cluster-name: elasticsearch
			cluster-nodes: 192.168.56.101:9300
	jackson:
		default-property-inclusion: non_null 
		在序列化的时候，这些null的字段就没有了，这个应该是配置那个使用ObjectMapper 这个类进行序列化与反序列化的
		
	
	
在chrome控制台上输入：
JSON.stringify({name: 'zhansan', age: 18})
输出"{"name":"zhangsan","age":18}"

JSON.parse("{\"name\":\"zhangsan\",\"age\":18}")
输出：{name:"zhangsan",age:18}


查询字符串  key=value&key1=value1
json对象 ｛key:"value", key1:"value1"｝
查询字符串==》json对象  ly.parse(查询字符串)
json对象--》查询字符串 ly.stringify(json对象)

json字符串: "{'key':'value', 'key1':'value1'}"
json字符串--》json对象 JSON.parse stringfify
	
	
现在来看分页：
比如你100页，当前页为25页
那么分页条是不是
上一页  23 24 25 26 27... 下一页
注意，当前页是不是在中间啊


注意：当前页，每页数据大小，总页数，这些都需要返回给前端，要不然这种分页条做不了
总页数，好像我一直都没写

还要做分页条，当前页是红色，即当前展示的页是激活状态
	
	
	
CREATE TABLE t_user  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `username` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '用户名',
  `password` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '密码，加密存储',
  `phone` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '注册手机号',
  `created` datetime(0) NOT NULL COMMENT '创建时间',
  `salt` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '密码加密的salt值',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `username`(`username`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 29 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '用户表' ROW_FORMAT = Compact;	

你看，这里还可以创建唯一索引UNIQUE KEY不可重复

密码保存前，要先加盐，再加密，每个用户都会随机生成一个盐，并把这个用户的盐存起来，原来安证通的写法，每个人的盐是一样的，写死在程序里面
，将来用户登录的时候，把用户输入的密码，跟用户的盐加上，再进行加密码，然后再跟数据库里面去比对，如果一致才允许登录



@Table(name = "tb_user")
public class User {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    /**
     * 用户名
     */
    @Length(min = 4,max = 15,message = "用户名只能在4~15位之间")
    private String username;

    /**
     * 密码
     */
    //@JsonIgnore  对象序列化为json字符串时，忽略该属性
    @Length(min = 6,max = 25,message = "密码只能在6~25位之间")
    private String password;



@GetMapping("check/{data}/{type}")
    public ResponseEntity<Boolean> checkUserData(@PathVariable("data") String data,@PathVariable(value = "type") Integer type){
        Boolean result = this.userService.checkData(data,type);
        if (result == null){
//            return ResponseEntity.status(HttpStatus.BAD_REQUEST).build();
            return ResponseEntity.badRequest().build();
        }
        return ResponseEntity.ok(result);
    }
参数不合法，这些直接通过403这样的状态进行返回，不再需要人工的写什么参数不合法，这样的文字了


安装SDK jar包（即往我们自己的仓库里面添加一个jar包，原来是通过命令的方式进行的）
我们需要把api_SDK中的两个依赖装入本地maven中，进入api_sdk目录，有两个项目需要处理：
然后进入到项目根目录：
mvn install -Dmaven.test.skip=true -Dgpg.skip=true

原来的安证通，直接手工拷进去，好low啊


发送短信的服务，也采用消息队列的方式，因为可能会有很多的微服务会需要用到发送短信的功能，你在一个微服务里面做一个接口，给其他微服务调用，这样耦合度还是太高，我们为什么不采用消息队列，
谁要发送短信，谁就往队列里面写入一个消息 ，然后短信微服务只要去监听这个消息就可以了，
是不是你短信多久才能发送成功，也不知道啊，那么别人的服务是不是一直得等着你消息发送成功了，后面的业务才能执行啊，肯定不行，所以我们为了解耦合，就是使用消息队列

<dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
		这个web启动器，里面就已经有tomcat了
		
@Configuration
public class SmsParamConfig {
	/**
	 * 短信验证码默认有效时间(秒)  ${sms.active_time}
	 */
	public static Long ACTIVE_TIME;
	@Value("${sms.active_time}")
	public void setACTIVE_TIME(Long aCTIVE_TIME) {
		ACTIVE_TIME = aCTIVE_TIME;
	}

	@Value("${sms.re_send_check}")
	public void setRE_SEND_CHECK(int rE_SEND_CHECK) {
		RE_SEND_CHECK = rE_SEND_CHECK;
	}
上面是我封装的，以后也不要再使用这种方式了，还是使用生成set get方法比较好

lombok以后也不要使用了，不是很好用

这个手机验证码，你发送给用户之后，你自己还要保存一份啊，是不是，要不然你怎么知道用户输入得对不对啊，那保存在服务器上的哪个位置呢？
如果保存在session中，我可能是分布式应用啊，那session又没共享，保存在session中肯定是不合理的，保存在数据库可行，但不可取，短信验证可能会发送很多次
验证码可能就只需要2-3分钟后，就没作用了，redis性能很高的


注意在redis中所有数据类型都是string
Spring Data Redis 提供了一个工具类：RedisTemplate。里面封装了对于Redis的五种数据结构的各种操作，包括：

- redisTemplate.opsForValue() ：操作字符串
- redisTemplate.opsForHash() ：操作hash
- redisTemplate.opsForList()：操作list
- redisTemplate.opsForSet()：操作set
- redisTemplate.opsForZSet()：操作zset

其它一些通用命令，如expire，可以通过redisTemplate.xx()来直接调用

5种结构：

- String：等同于java中的，`Map<String,String>`
- list：等同于java中的`Map<String,List<String>>`
- set：等同于java中的`Map<String,Set<String>>`
- sort_set：可排序的set
- hash：等同于java中的：`Map<String,Map<String,String>>


使用redisTemplate，他会默认给你序列化，会使用jdk的序列工具来序列化，序列化出来的东西，乱七八糟的，完全不知道是什么东西，给存入redis里面了，就是一些问号之类的
虽然存入redis中，你使用redis客户端工具去查看，人是看不懂的，不过你用程序去读出来
程序还是看得懂的，还是可以正常读出来
，
不过存这种乱七八糟的乱码一样的存入redis，将来你去调试程序，肯定非常不方便啊
而且这种乱码一样的，占用太大的内存了

序列化的工具有很多，JdkSerializationRedisSerializer
Jackson2JsonRedisSerializer  StringRedisSerializer我们通常使用StringRedisSerializer
因为redis中所有的数据都是string类型存储的，当然使用这个了，你本来是什么内容就存什么内容
最大化的利用空间

JdkSerializationRedisSerializer这个效率是最高的，但是占用比较大的存储空间
StringRedisSerializer性能效率也是很不错的

你用序列化工具，你需要对key去序列化，需要对value序列化，那么redis已经想到了你需要用到这些功能
所以给你提供了一个StringRedisTemplate

存储到redis中的验证码，数据结构不应该是   手机号码：验证码
因为如果很多模块都是你这么设计的话，那么别人会把你存入的验证码给覆盖掉，所以应该采用
private static final String key_prefix = "user:verify:";
使用这种前缀来进行区分

CodeUtil这个是用户密码加盐，加密相关的，肯定不能放到common工程里面去，这样你的算法
别的团队也就知道了，肯定不能放公共工程里面去的，只能单独放在user工程里面


User user = new User();
user.setId(null);//设置为空，防止别人注入问题
user.setName(name);
user.setPassword(password);

userMapper.save(user);



前台页面校验，真的不是很靠谱，因为整个登录，或者后续的所有请求，全都可以通过类似postman这样的工具来进行
比如：postman里面打开两个sheet页，一个专门请求获取验证码接口，一个拼接好用户注册接口的请求
是不是就可以把验证码接口返回的验证码，重新放入用户注册接口进行注册啊，肯定是可以的啊
这样是不是就存在批量垃圾注册的问题啊，所以引入hibernate-validate校验工具，这样垃圾注册的问题有明显的好转

所以前端需要做校验，后台也依然需要做校验，
后台校验，比如表单字段较少，你可以一个一个判断，如果一个表单50，100个，你一个一个去写吗？》
会写半天，写死去，所以这个时候，我们引入hibernate-validate
专门做数据校验的，hibernate是一个组织，也提供了很多框架，比如
hibernate validator就是其中一个，使用注解就可以了，非常简单



@Valid 表示：你在什么地方需要校验，你在什么地方加上这个注解就可以了
 @PostMapping("register")
    public ResponseEntity<Void> register(@Valid User user, @RequestParam("code") String code){
        Boolean result = this.userService.register(user,code);
        if(result == null || !result){
            return ResponseEntity.status(HttpStatus.BAD_REQUEST).build();
        }
        return ResponseEntity.status(HttpStatus.CREATED).build();
    }
@Valid 我现在只加上这个注解，加上引入hibernate validator包，我并没有去配置
hibernate与spring的任何关联啊，现在请求参数不合法，怎么自动被hibernate给拦截了呢

这个时候我们需要去看一下spring的注解驱动了
看spring mvc下面的annotationdriven 

注入推荐使用的映射器和适配器
RequestMappingHandlerMapping 映射器
RequestMapperHandlerAdaptor 适合器
<mvc:annotation-driven />

查询用户接口返回：
{
    "id": 6572312,
    "username":"test",
    "phone":"13688886666",
    "created": 1342432424
}
这个里面是不是没有盐，没有password了啊，就是通过
@JsonIgnore
    @Length(min = 6,max = 25,message = "密码只能在6~25位之间")
    private String password;
你只要返回一个user对象，那么就会自动过滤掉此字段



今天来讲无状态登录，有状态登录即session，如果上亿的用户，那么你这种
session全保存在服务器上，服务器根本扛不过来，所以才有无状态登录了
tomcat现在提供了session共享，但是每一台服务器上都保存的是全量的session，
这种压力也很大啊，这种传统的方式已经不可行了

作为服务器端完全不用去保存这个登录状态，客户端自我介绍就可以了
使用无状态登录，token的安全性就非常重要了，为了防止别人伪造，我们采用
jwt+rsa非对称加密  方案

JWT是token的一种解决方案，oauth2也是token的一种解决方案

/**
     * @PostConstruct :在构造方法执行之后执行该方法
     */
    @PostConstruct
    public void init(){}
	
	还有@PreConstruct
注意这两个注解，都是java提供的，不是spring提供的，
有这样的注解，你使用@Autowired 注入这个对象的时候，就会执行这个方法


@Controller
public class AuthController {
 @PostMapping("accredit")
    public ResponseEntity<Void> authentication(
            @RequestParam("username") String username,
            @RequestParam("password") String password,
            HttpServletRequest request,
            HttpServletResponse response
    ){}

@Controller 所有的工程上面都没有声明路径，其实是在zuul网关里面声明了，老师只是写简单demo，我们真正的工程，还是要写，因为这个路径我们可以用来声明为不同的模块，
一个工程又不只有一张表，一个controller类，而且不写@RequestMapping("user") swagger打开都有问题

zuul:
	prefix: /api
	routes:
		item-service: /item/** #路由到商品的微服务
		search-service: /search/**
		user-service: /user/**
		auth-service: /auth/**
		
auth-service虽然配置文件配的是这个名字，但工程名字是leyou-auth-service
是因为在leyou-auth-service这个微服务模块里面的application.yml里面配的是
server:
	port: 8087
spring:
	application:
		name: auth-service


// 设置域名的cookie
cookie.setDomain(getDomainName(request));
这个其实就是设置域名，比如你京东的设置京东的域名，天猫的设置天猫的域名，
这样可以做到互不干扰


我们现在的分布式微服务架构，获取域名有问题
server {
        listen       80;
        server_name  api.leyou.com
		proxy_set_header X-Forwarded-Host $host;
        proxy_set_header X-Forwarded-Server $host;
        proxy_set_header Host $host;  加一个这样的配置，
		
		加一个这样的配置nginx转发的时候，就会携带域名，转发到网关了，网关
		就可以获取到域名了，但是，此时，网关再转发至相应的微服务时，域名又没有了
		所以需要在网关微服务的application.yml配置文件中加上
zuul:
	prefix: /api
	routes:
		item-service: /item/** #路由到商品的微服务
		search-service: /search/**
		user-service: /user/**
		auth-service: /auth/**
	add-host-header: true 设置这个，网关转发至所有的微服务，微服务去都可以获取到域名
	sensitive-headers:  #啥都不写，即为覆盖默认网关里面默认的忽略头信息
		网关转发到微
		服务，那么微服务，就可以获取到域名，成功设置cookie中的域名了

现在全部配置好了，cookie还是没成功写入，我们接下来看一下
zuul网关给我们提供了一个默认的过滤器  
PreDecorationFilter.java通过分析源码，我们看到他默认是忽略了请求头信息
所以我们需要在配置文件里面配置开启头信息
sensitive-headers:  #啥都不写，即为覆盖默认网关里面默认的忽略头信息 ，
覆盖默认敏感头信息

chorme还有搜索的功能，比如搜索getCustomerList在哪个js文件或者哪个html文件里面有使用到

现在来获取cookie了，可以通过CookieUtils来获取，但是我们现在不这么做
使用 @CookieValue来获取

 /**
     * 用户验证
     * @param token
     * @return
     */
    @GetMapping("verify")
    public ResponseEntity<UserInfo> verifyUser(@CookieValue("LY_TOKEN") String token,HttpServletRequest request,
                                               HttpServletResponse response){
        try{
            //1.从token中解析token信息
            UserInfo userInfo = JwtUtils.getInfoFromToken(token,this.properties.getPublicKey());
            //2.解析成功要重新刷新token
            token = JwtUtils.generateToken(userInfo,this.properties.getPrivateKey(),this.properties.getExpire());
            //3.更新Cookie中的token
            CookieUtils.setCookie(request,response,this.properties.getCookieName(),token,this.properties.getCookieMaxAge());
            //4.解析成功返回用户信息
            return ResponseEntity.ok(userInfo);
        }catch (Exception e){
            e.printStackTrace();
        }
        //5.出现异常,相应401
        return ResponseEntity.status(HttpStatus.UNAUTHORIZED).build();
    }
}
在显示用户名的地方，目前还是未登录的状态，这个地方控制已经登录就显示用户名，未登录就显示用户未登录
此时调用上面的verify接口来校验，是否已经登录过，上面那个方法就从cookie中获取token看是否登录成功


刷新jwt中有效时间
JwtUtils.generateToken(user, this.jwtProperties.getPrivateKey)

刷新cookie中的有效时间

就是相当于重新生成token,重新写入cookie,保证用户在操作的情况下，就不过期

传统登录都是有状态登录，在服务器端保存session
无状态不需要session,把登录状态保存在cookie中